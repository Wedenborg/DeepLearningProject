{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bu1Wy6Xb81Sn"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Credits\n",
    "\n",
    "This is heavily influenced from https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZW0gaQO81Sq"
   },
   "source": [
    "# CIFAR-10\n",
    "\n",
    "In thins notebook you need to put what you have learned into practice, and create your own convolutional classifier for the CIFAR-10 dataset.\n",
    "\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "![cifar10](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/cifar10.png?raw=1)\n",
    "\n",
    "\n",
    "In order to train a classifier the following steps needs to be performed:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "We will help you along the way.\n",
    "We indicate the places you need to modify the code with `# Your code here!`.\n",
    "It is however a good idea to read the entire assignment before you begin coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htyg7xxN81St"
   },
   "source": [
    "## 1. Loading and normalizing CIFAR10\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3u2GIWr81Su"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xx5SHRkm81S0"
   },
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "**NB** Modify the code below to only use a small part of the dataset if your computer is very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "QZeTujLC81S3",
    "outputId": "656d4f5a-d1cc-4aa8-9fa6-94ac83d6c12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "used classes: ['cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                          (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "used_categories = range(len(classes))\n",
    "\n",
    "## USE CODE BELOW IF YOUR COMPUTER IS TOO SLOW\n",
    "reduce_dataset = True\n",
    "if reduce_dataset:\n",
    "    used_categories = (3, 5) # cats and dogs\n",
    "\n",
    "    classes = [classes[i] for i in used_categories]\n",
    "    new_train_data = []\n",
    "    new_train_labels = []\n",
    "\n",
    "    new_test_data = []\n",
    "    new_test_labels = []\n",
    "    for i, t in enumerate(used_categories):\n",
    "        new_train_data.append(trainset.data[np.where(np.array(trainset.targets) == t)])\n",
    "        new_train_labels += [i for _ in range(new_train_data[-1].shape[0])]\n",
    "\n",
    "        new_test_data.append(testset.data[np.where(np.array(testset.targets) == t)])\n",
    "        new_test_labels += [i for _ in range(new_test_data[-1].shape[0])]\n",
    "\n",
    "    new_train_data = np.concatenate(new_train_data, 0)\n",
    "    trainset.data = new_train_data#.reshape((10000, 3, 32, 32))\n",
    "    trainset.targets = new_train_labels\n",
    "#    trainset.data = np.resize(trainset.data)\n",
    "\n",
    "    new_test_data = np.concatenate(new_test_data, 0)\n",
    "    testset.data = new_test_data\n",
    "    testset.targets = new_test_labels\n",
    "#    testset.data = testset.data.reshape((2000, 3, 32, 32))\n",
    "#    testset.data = np.moveaxis(testset.data, [-1, 1], [1, -1])\n",
    "#    testset.data = np.moveaxis(testset.data, [-1, -2], [-2, -1])\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2) # trainset is a torch feature\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "train_data_iter = iter(trainloader)\n",
    "test_data_iter = iter(testloader)\n",
    "print('used classes:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "JDHkc52L81S9",
    "outputId": "d06106f2-f6b5-46be-9b46-07637861aa8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(10000, 32, 32, 3)\n",
      "10000\n",
      "\n",
      "Test data\n",
      "(2000, 32, 32, 3)\n",
      "2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data\")\n",
    "print(trainset.data.shape)\n",
    "print(len(trainset.targets))\n",
    "print()\n",
    "\n",
    "print(\"Test data\")\n",
    "print(testset.data.shape)\n",
    "print(len(testset.targets))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSA1h94681TB"
   },
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "njJy0klP81TD",
    "outputId": "693811f4-a8c1-41ce-d885-b3fbbaca8b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane   car   car plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell multiple time to see more samples\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\" show an image \"\"\"\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "images, labels = train_data_iter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt3BVFMF81TI"
   },
   "source": [
    "## 2. Define a Convolutional Neural Network\n",
    "\n",
    "**Assignment 1:** Define a convolutional neural network. \n",
    "You may use the code from previous notebooks.\n",
    "We suggest that you start with a small network, and make sure that everything is working.\n",
    "Once you can train successfully come back and improve the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding the shape\n",
    "trainset.data.shape\n",
    "# 10.000 pictures, 32x32 pixels, 3 colors (so all colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_1): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
      "  (l_1): Linear(in_features=1536, out_features=100, bias=True)\n",
      "  (l_out): Linear(in_features=100, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "\n",
    "# hyperameters of the model\n",
    "num_classes = 10\n",
    "channels = trainset.data.shape[1]\n",
    "height = trainset.data.shape[2]\n",
    "width = trainset.data.shape[3] \n",
    "num_filters_conv1 = 16\n",
    "kernel_size_conv1 = 5 # [height, width]\n",
    "stride_conv1 = 1 # [stride_height, stride_width]\n",
    "num_l1 = 100\n",
    "\n",
    "\n",
    "padding_conv1 = 2 # so we keep dim 32x32\n",
    "   \n",
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_conv1 + 2*padding_conv1) / stride_conv1 + 1)\n",
    "# Function from https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d (for me)\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Convolution \n",
    "        super(Net, self).__init__()\n",
    "        out_dim = (height - kernel_size_conv1 + 2*padding_conv1) / stride_conv1 + 1 # Adding 0's as padding round the pic to avoid dim loss \n",
    "        self.conv_1 = Conv2d(in_channels=channels,\n",
    "                            out_channels=num_filters_conv1,\n",
    "                            kernel_size=kernel_size_conv1,\n",
    "                            stride=stride_conv1,\n",
    "                            padding = padding_conv1)      # 3 channels in, output channel pr filter\n",
    "                            # This gives our ned 3D matrix if we have added the padding (we have here)\n",
    "        \n",
    "        self.conv_out_height = compute_conv_dim(height) # The height and with we get from computing the formula from the website\n",
    "        self.conv_out_width = compute_conv_dim(width)\n",
    "        \n",
    "        # add dropout to network\n",
    "        self.dropout = Dropout2d(p=0.5)\n",
    "        self.l1_in_features = num_filters_conv1 * self.conv_out_height * self.conv_out_width\n",
    "        #self.l1_in_features = num_filters_conv1 * 32 * 32 # So our vector has the correct dim (32x32)\n",
    "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
    "                          out_features=num_l1,\n",
    "                          bias=True)\n",
    "        self.l_out = Linear(in_features=num_l1, \n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "    \n",
    "    def forward(self, x): # x.size() = [batch, channel, height, width]\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        x = relu(self.conv_1(x))\n",
    "        # torch.Tensor.view: http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        #   Returns a new tensor with the same data as the self tensor,\n",
    "        #   but of a different size.\n",
    "        # the size -1 is inferred from other dimensions \n",
    "        x = x.view(-1, self.l1_in_features)\n",
    "        #x = self.dropout(relu(self.l_1(x)))\n",
    "        x = relu(self.l_1(x))\n",
    "        return softmax(self.l_out(x), dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10]),\n",
       " tensor([[0.1100, 0.1184, 0.1007,  ..., 0.0853, 0.0829, 0.0924],\n",
       "         [0.1052, 0.1054, 0.0990,  ..., 0.0993, 0.0876, 0.0908],\n",
       "         [0.0969, 0.1036, 0.1053,  ..., 0.0918, 0.0902, 0.0912],\n",
       "         ...,\n",
       "         [0.1022, 0.1026, 0.0964,  ..., 0.0939, 0.0966, 0.0915],\n",
       "         [0.1062, 0.0932, 0.1040,  ..., 0.0970, 0.0984, 0.0891],\n",
       "         [0.0992, 0.1018, 0.0960,  ..., 0.0869, 0.0940, 0.0925]],\n",
       "        grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We test with dummy data! \n",
    "x = np.random.normal(0,1, (10000, 32, 32, 3)).astype('float32')\n",
    "out = net(Variable(torch.from_numpy(x)))\n",
    "out.size(), out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-IUg3sq81TQ"
   },
   "source": [
    "## 3. Define a Loss function and optimizer\n",
    "\n",
    "**Assignment 2:** Implement the criterion and optimizer. \n",
    "We suggest Classification Cross-Entropy loss and SGD with momentum.\n",
    "You might need to experiment a bit with the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48AX85QP81TR"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9) \n",
    "criterion = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WneIN7C81TV"
   },
   "source": [
    "## 4. Train the network\n",
    "\n",
    "**Assignment 3:** Finish the training loop below. \n",
    "Start by using a small number of epochs (e.g. 3).\n",
    "Even with a low number of epochs you should be able to see results that are better than chance.\n",
    "When everything is working increase the number of epochs to find out how good your network really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkUanRRb81TW",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2a194c0aace0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;31m#print(trainset.data.dtype)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;31m# compute gradients given loss - Backwards propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-41fe47ccd4dc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# x.size() = [batch, channel, height, width]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;31m# torch.Tensor.view: http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m#   Returns a new tensor with the same data as the self tensor,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 340\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### NOTE TO READER ###\n",
    "# My computer couldnt manage to run the program and finish the training, \n",
    "# but I'm fairly confident the code itself is working. For the same reason, \n",
    "# the next assignment on improving the model has not been made.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 9\n",
    "num_epoch = 3  # Initializing on this\n",
    "num_samples_train = trainset.data.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = testset.data.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "losses = []\n",
    "\n",
    "trainset.targets = np.asarray(trainset.targets, dtype = 'uint8')\n",
    "testset.targets = np.asarray(testset.targets, dtype = 'uint8')\n",
    "\n",
    "get_slice = lambda i, size: range(i * size, (i + 1) * size)\n",
    "\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() #my code\n",
    "\n",
    "        # forward + backward + optimize parameters\n",
    "        ## Train\n",
    "        cur_loss = 0\n",
    "        net.train()\n",
    "        \n",
    "        for i in range(num_batches_train): # Forward propagation which we made with net\n",
    "            slce = get_slice(i, batch_size)\n",
    "            #print(trainset.data.dtype)\n",
    "            x_batch = Variable(torch.from_numpy(trainset.data[slce]).float())\n",
    "            output = net(x_batch)\n",
    "        \n",
    "            # compute gradients given loss - Backwards propagation\n",
    "            #print(np.asarray(trainset.targets, dtype = 'uint8').dtype)\n",
    "            target_batch = Variable(torch.from_numpy(trainset.targets[slce])).long()\n",
    "            batch_loss = criterion(output, target_batch)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            cur_loss += batch_loss   \n",
    "        losses.append(cur_loss / batch_size)\n",
    "###\n",
    "        net.eval()\n",
    "    ### Evaluate training\n",
    "        train_preds, train_targs = [], []\n",
    "        for i in range(num_batches_train):\n",
    "            slce = get_slice(i, batch_size)\n",
    "            x_batch = Variable(torch.from_numpy(trainset.data[slce]))\n",
    "        \n",
    "            output = net(x_batch)\n",
    "            preds = torch.max(output, 1)[1]\n",
    "        \n",
    "            train_targs += list(trainset.targets[slce])\n",
    "            train_preds += list(preds.data.numpy())\n",
    "    \n",
    "    ### Evaluate validation\n",
    "        val_preds, val_targs = [], []\n",
    "        for i in range(num_batches_valid):\n",
    "            slce = get_slice(i, batch_size)\n",
    "            x_batch = Variable(torch.from_numpy(testset.data[slce]))\n",
    "        \n",
    "            output = net(x_batch)\n",
    "            preds = torch.max(output, 1)[1]\n",
    "            val_preds += list(preds.data.numpy())\n",
    "            val_targs += list(testset.targets[slce])\n",
    "\n",
    "        train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "        valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
    "    \n",
    "        train_acc.append(train_acc_cur)\n",
    "        valid_acc.append(valid_acc_cur)\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.data[0]\n",
    "    if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / 1000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qAsbC8I81Ta"
   },
   "source": [
    "## 5. Test the network on the test data\n",
    "\n",
    "Now we need to check if the network has learnt anything at all.\n",
    "We will check this by predicting the class label that the neural network outputs, and checking it against the ground truth.\n",
    "If the prediction is correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LT0RoAC81Tc"
   },
   "outputs": [],
   "source": [
    "images, labels = test_data_iter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()\n",
    "\n",
    "print('GroundTruth:  ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted:    ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISA6LJJO81Tg"
   },
   "source": [
    "Let us look at how the network performs on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Smv6_BwF81Ti"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
    "    testset.test_data.shape[0], 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMZRvhaW81Tl"
   },
   "source": [
    "Hopefully the network is better than chance, which is $\\frac{1}{\\text{number of classes}}$ accuracy (randomly picking\n",
    "a class).\n",
    "\n",
    "\n",
    "We can also examine which class the network found the most difficult (makes more sense if you have many clases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqVTQgKq81Tl"
   },
   "outputs": [],
   "source": [
    "class_total = list(0. for i in range(len(classes)))\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    \n",
    "    for i in range(len(c)):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i].numpy()\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of {:5s} : {:5.2f} %'.format(\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocnQOBAl81Tn"
   },
   "source": [
    "**Assignment 4:** \n",
    "1. Go back and improve performance of the network. \n",
    " * If you are using all 10 classes you should get a test accuracy above 55%, but see how much further you can get it!\n",
    " * If you are using only 2 classes (e.g. cat and dog) you should get a test accuracy above 60%, but see how much further you can get it!\n",
    "\n",
    "2. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.\n",
    "Did anything surprise you during the exercise?\n",
    "\n",
    "3. Write down key lessons/insights you got (if any) during this exercise.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Nzefavy81To"
   },
   "source": [
    "# Training on GPU\n",
    "\n",
    "**Optional Assignment:**\n",
    "If you have a GPU we suggest that you try and rewrite the code above to run on the GPU\n",
    "___\n",
    "\n",
    "Just like how you transfer a Tensor on to the GPU, you transfer the neural net onto the GPU.\n",
    "This will recursively go over all modules and convert their parameters and buffers to CUDA tensors:\n",
    "\n",
    "```\n",
    "    net.cuda()\n",
    "```\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step to the GPU too:\n",
    "\n",
    "```\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "```\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? \n",
    "Because your network is realllly small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8mEIylU81Tp"
   },
   "source": [
    "# Michael Nielsen book exercise of own choice\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 5:** Pick an exercise of own choice from [Michael Nielsens book](http://neuralnetworksanddeeplearning.com/)\n",
    "\n",
    "This is the first exercise of the first chapter\n",
    "\n",
    "Prompt:\\\n",
    "Suppose we take all the weights and biases in a network of perceptrons, and multiply them by a positive constant, c>0. Show that the behaviour of the network doesn't change.\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "Perceptrons can only ever output 0 or 1, depending on whether the input vector times the weight plus the bias is positive or zero or smaller than zero. This expression can be written as\n",
    "$$c⋅w⋅x + c⋅b$$\n",
    "where w is the weights, x is the input vector, b is the bias and c is the positive constant. This can easily be rewritten as \n",
    "$$c * (⋅w⋅x + b)$$\n",
    "Now, it should be clear that the output of any perceptron cannot change as the strictly positive constant c cannot change the sign, which is all that matters for the perceptron.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of 4.3-EXE-CIFAR-10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
